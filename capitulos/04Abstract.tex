\chapter*{}

\section*{Abstract}

We are generating more data than ever: according to the World Wide Web Size, the figure of a Zettabyte, that is, 1,099,511,627,776 GB, was reached in 2016. In 2017, each minute, more than 3.8 million searches on google, more than 1.5 million songs were listened to on Spotify, more than 29 million messages were sent by whatsapp, 400 hours of video are uploaded to YouTube ... Against this data, the use of traditional tools is not the most appropriate for data analysis.\\

When the amount of information is too large to be treated by a single machine, it must be parallelized. Spark is a distributed processing framework in memory that makes use of the MapReduce programming paradigm to perform distributed computing in a cluster. In this report, by becoming familiar with this tool, we will learn how to work with Spark and how Spark works

{\setlength{\parskip}{30mm}
\section*{Keywords}
}
Spark, Big Data, data, scala, hadoop, Apache, cl√∫ster, RDD, Dataset, DataFrames, Shuffle